{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f2e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-win_amd64.whl (423.2 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.18.0-cp38-cp38-win_amd64.whl (912 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.40.0-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.14.0-py3-none-any.whl (131 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=0232d584415299ed8fed5d6d7c36cade50f92290609fe58e502c1d19a5f58d39\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\f1\\60\\77\\22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=c113bc76721134a27f5411a0a7dabb8794440444045a260720d46b9c4de9483a\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.14.0 astunparse-1.6.3 cachetools-4.2.2 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.40.0 h5py-3.1.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.18.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f8e9ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.3.56-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.3.56\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9e2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "toproi = 100\n",
    "bottomroi = 300\n",
    "rightroi = 150\n",
    "leftroi = 350\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2018f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def puttext(image, text, org, font, fontScale, color, thickness):\n",
    "    cv2.putText(image, text, org, font, fontScale, color, thickness)\n",
    "    \n",
    "def makingrectangle(image, start_point, end_point, color, thickness):\n",
    "    cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "    \n",
    "def show(window_name, image):\n",
    "    cv2.imshow(window_name, image)\n",
    "\n",
    "def segment_hand(frameinstance, threshold=25):\n",
    "    global background\n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frameinstance)\n",
    "    _ , threshold = cv2.threshold(diff, threshold,255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(threshold.copy(),\n",
    "    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        return (threshold, hand_segment_max_cont)\n",
    "    \n",
    "def detectinghandfl300(hand, copiedframeinstance, rightroi,toproi, frameinstancesnum, curelement):\n",
    "    threshold, hand_segment = hand\n",
    "    cv2.drawContours(copiedframeinstance, [hand_segment + (rightroi,toproi)], -1, (255, 0, 0),1)\n",
    "    puttext(copiedframeinstance, str(frameinstancesnum)+\"For\" + str(curelement),(70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    show(\"threshold Hand Image\", threshold)\n",
    "    \n",
    "\n",
    "def detectinghandgl300(hand, copiedframeinstance, rightroi,toproi, frameinstancesnum, curelement, takenimgs):    \n",
    "    threshold, hand_segment = hand\n",
    "    cv2.drawContours(copiedframeinstance, [hand_segment + (rightroi,toproi)], -1, (255, 0, 0),1)\n",
    "    puttext(copiedframeinstance, str(frameinstancesnum), (70, 45),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    puttext(copiedframeinstance, str(takenimgs) + 'images' +\"For\"+ str(curelement), (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255), 2)\n",
    "    return threshold\n",
    "    \n",
    "def ls300(variable):\n",
    "    if(variable<=200):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def checknone(variable):\n",
    "    if(variable is None):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def cal_accum_avg(frameinstance, accumulated_weight):\n",
    "    global background\n",
    "    if background is None:\n",
    "        background = frameinstance.copy().astype(\"float\")\n",
    "        return None\n",
    "    cv2.accumulateWeighted(frameinstance, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "684e6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "frameinstancesnum = 0\n",
    "curelement = 7\n",
    "takenimgs = 0\n",
    "\n",
    "while True:\n",
    "    ret, frameinstance = camera.read()\n",
    "    frameinstance = cv2.flip(frameinstance, 1)\n",
    "    copiedframeinstance = frameinstance.copy()\n",
    "    roi = frameinstance[toproi:bottomroi, rightroi:leftroi]\n",
    "    frameinstancegray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    frameinstancegray = cv2.GaussianBlur(frameinstancegray, (9, 9), 0)\n",
    "    \n",
    "    \n",
    "    if frameinstancesnum < 60:\n",
    "        cal_accum_avg(frameinstancegray, accumulated_weight)\n",
    "        if frameinstancesnum <= 59:\n",
    "            text = \"Getting the background...\"\n",
    "            puttext(copiedframeinstance, text,(80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "            \n",
    "            \n",
    "    elif ls300(frameinstancesnum): \n",
    "        hand = segment_hand(frameinstancegray)\n",
    "        text = \"Adjust Hand Gesture for\" + str(curelement)\n",
    "        puttext(copiedframeinstance, text, (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),2)\n",
    "        if checknone(hand):\n",
    "            detectinghandfl300(hand, copiedframeinstance, rightroi,toproi, frameinstancesnum, curelement)    \n",
    "            \n",
    "            \n",
    "        \n",
    "    else: \n",
    "        \n",
    "        hand = segment_hand(frameinstancegray)\n",
    "        if checknone(hand):\n",
    "            threshold = detectinghandgl300(hand, copiedframeinstance, rightroi,toproi, frameinstancesnum, curelement, takenimgs)\n",
    "            show(\"Threshold Hand Image\", threshold)\n",
    "            if ls300(takenimgs):\n",
    "                text = r\"F:\\\\capstonetrying\\\\gesture\\\\test\\\\\"+str(curelement)+\"\\\\\" + str(takenimgs) + '.jpg'\n",
    "                cv2.imwrite(text, threshold)   \n",
    "            else:\n",
    "                break\n",
    "            takenimgs +=1 \n",
    "        else:\n",
    "            text = 'No hand detected...'\n",
    "            puttext(copiedframeinstance, text, (200, 400),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "            \n",
    "    makingrectangle(copiedframeinstance, (leftroi, toproi), (rightroi,bottomroi), (255,128,0), 3)\n",
    "    puttext(copiedframeinstance, \"Hand sign recognition_ _ _\", (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    frameinstancesnum += 1\n",
    "    show(\"Sign Detection\", copiedframeinstance)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e21637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7100 images belonging to 10 classes.\n",
      "Found 400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = r\"F:\\\\capstonetrying\\\\gesture\\\\train\"\n",
    "test_path = r\"F:\\\\capstonetrying\\\\gesture\\\\test\"\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f40f5467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\n"
     ]
    }
   ],
   "source": [
    "print(len(train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd56dc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "imgs, labels = next(train_batches)\n",
    "print(labels)\n",
    "print(len(imgs[2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab432964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(10,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ad15b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 414,346\n",
      "Trainable params: 414,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd7a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e30bbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "710/710 [==============================] - 148s 207ms/step - loss: 0.2376 - accuracy: 0.9787 - val_loss: 2.2783 - val_accuracy: 0.5400\n",
      "Epoch 2/10\n",
      "710/710 [==============================] - 112s 158ms/step - loss: 9.7110e-04 - accuracy: 1.0000 - val_loss: 2.4409 - val_accuracy: 0.5450\n",
      "Epoch 3/10\n",
      "710/710 [==============================] - 114s 161ms/step - loss: 5.1345e-04 - accuracy: 1.0000 - val_loss: 2.5047 - val_accuracy: 0.5475\n",
      "Epoch 4/10\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 3.3931e-04 - accuracy: 1.0000 - val_loss: 2.5593 - val_accuracy: 0.5500\n",
      "Epoch 5/10\n",
      "710/710 [==============================] - 110s 155ms/step - loss: 2.5287e-04 - accuracy: 1.0000 - val_loss: 2.5886 - val_accuracy: 0.5500\n",
      "Epoch 6/10\n",
      "710/710 [==============================] - 118s 167ms/step - loss: 1.9861e-04 - accuracy: 1.0000 - val_loss: 2.6404 - val_accuracy: 0.5500\n",
      "Epoch 7/10\n",
      "710/710 [==============================] - 120s 169ms/step - loss: 1.6406e-04 - accuracy: 1.0000 - val_loss: 2.6741 - val_accuracy: 0.5550\n",
      "Epoch 8/10\n",
      "710/710 [==============================] - 135s 190ms/step - loss: 1.3884e-04 - accuracy: 1.0000 - val_loss: 2.7054 - val_accuracy: 0.5550\n",
      "Epoch 9/10\n",
      "710/710 [==============================] - 142s 199ms/step - loss: 1.2000e-04 - accuracy: 1.0000 - val_loss: 2.7170 - val_accuracy: 0.5525\n",
      "Epoch 10/10\n",
      "710/710 [==============================] - 129s 182ms/step - loss: 1.0582e-04 - accuracy: 1.0000 - val_loss: 2.7546 - val_accuracy: 0.5575\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batches, epochs=10,  validation_data = test_batches)\n",
    "#callbacks=[reduce_lr, early_stop],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2914e6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0fe6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b93e8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounded test labels [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "preds = np.round(model.predict(test_batches),0)\n",
    "print(\"rounded test labels\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df86bd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 1.5265294313430786; accuracy of 69.9999988079071%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"F:\\\\capstonetrying\\\\New folder (2)\\\\model\\\\model_json.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"F:\\\\capstonetrying\\\\New folder (2)\\\\model\\\\model_weights.h5\")\n",
    "model.save(\"F:\\\\capstonetrying\\\\model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f48f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41dc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r\"F:\\\\capstonetrying\\\\model.h5\")\n",
    "\n",
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 150\n",
    "ROI_left = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f720de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "    global background\n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bef33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(frame, threshold=25):\n",
    "    global background\n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "    _ , thresholded = cv2.threshold(diff, threshold, 255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        return (thresholded, hand_segment_max_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf0c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "num_frames =0\n",
    "word_dict = {0:'Zero',1:'One',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_copy = frame.copy()\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    if num_frames < 70:   \n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        cv2.putText(frame_copy, \"Getting the Background...\", (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    else: \n",
    "        hand = segment_hand(gray_frame)\n",
    "        if hand is not None:  \n",
    "            thresholded, hand_segment = hand\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right,ROI_top)], -1, (255, 0, 0),1)\n",
    "            cv2.imshow(\"Thesholded Hand Image\", thresholded)\n",
    "            thresholded = cv2.resize(thresholded, (64, 64))\n",
    "            thresholded = cv2.cvtColor(thresholded,cv2.COLOR_GRAY2RGB)\n",
    "            thresholded = np.reshape(thresholded,(1,thresholded.shape[0],thresholded.shape[1],3))\n",
    "            pred = model.predict(thresholded)\n",
    "            cv2.putText(frame_copy, word_dict[np.argmax(pred)], (170, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,ROI_bottom), (255,128,0), 3)\n",
    "    num_frames += 1\n",
    "    cv2.putText(frame_copy, \"---SignHGD Project---\",\n",
    "    (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4412b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f20bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
